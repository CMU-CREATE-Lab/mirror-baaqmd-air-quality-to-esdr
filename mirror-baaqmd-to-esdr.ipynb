{
 "metadata": {
  "name": "",
  "signature": "sha256:ea63027bd7dd945f9d533764d4cd2890287f1c2b587660d63cfc2d3f50ecaa61"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO:\n",
      "\n",
      "- Get remaining 8 sites (see https://mail.google.com/mail/u/0/#sent/14d7c8811efa5b86?compose=14d7d7c04d888342)\n",
      "- create site feed\n",
      "- upload historical data \n",
      "- auto-upload recent data (daily every 5 mins, 2, 4, 8, 16, 32, 64\n",
      "- 1/2 + 1/4 + 1/8 ...\n",
      "- 1/3 + 2/9 + 4/27 ...\n",
      "- 1/4 + 3/16 + 9/64 ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime, re, time, urllib2\n",
      "from dateutil import tz\n",
      "from dateutil import rrule\n",
      "\n",
      "# scrapy web scraper\n",
      "# To install, run\n",
      "# !pip install scrapy\n",
      "# then restart kernel\n",
      "# If you see an error about zope version, double-check that you restarted the kernel\n",
      "from scrapy.selector import Selector\n",
      "\n",
      "def exec_ipynb(url):\n",
      "    import json, re, urllib2\n",
      "    nb = (urllib2.urlopen(url) if re.match(r'https?:', url) else open(url)).read()\n",
      "    exec '\\n'.join([''.join(cell['input']) for cell in json.loads(nb)['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
      "\n",
      "exec_ipynb('python-utils/esdr-library.ipynb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First time uploading, create a new client like so:\n",
      "\n",
      "# Esdr.save_client('esdr-auth-baaqm-uploader.json', 'BAAQMD uploader 2 for timemachine1')\n",
      "\n",
      "# and then follow the directions it prints, which include visiting esdr.cmucreatelab.org and creating\n",
      "# a client with given parameters, and also editing esdr-auth-baaqm-uploader.json to include your\n",
      "# username and password\n",
      "\n",
      "# Do not add esdr-auth-baaqm-uploader.json to the git repo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "esdr = Esdr('esdr-auth-baaqm-uploader.json')\n",
      "product = esdr.get_or_create_product('BAAQMD', 'BAAQMD', 'Sensor network run by Bay Area Air Quality Management District')\n",
      "product"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "{u'created': u'2015-05-28T16:45:17.000Z',\n",
        " u'creatorUserId': 3,\n",
        " u'defaultChannelSpecs': {},\n",
        " u'description': u'Sensor network run by Bay Area Air Quality Management District',\n",
        " u'id': 35,\n",
        " u'modified': u'2015-05-28T16:45:17.000Z',\n",
        " u'name': u'BAAQMD',\n",
        " u'prettyName': u'BAAQMD',\n",
        " u'vendor': u'BAAQMD'}"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "baaqmd_tz = tz.tzoffset(\"PST\", -8 * 3600)\n",
      "\n",
      "# BAAQMD always reports in Pacific Standard Time,\n",
      "# even when the Bay Area observes Pacific Daylight Time during the summer.\n",
      "\n",
      "# In other words, BAAQMD times look correct in the winter, but are appear\n",
      "# to be one hour behind people's clocks during the summer.\n",
      "\n",
      "# For example, if during the summer, if\n",
      "# BAAQMD reports 3pm Pacific Standard Time,\n",
      "# that would correspond to 4pm Pacific Daylight Time.\n",
      "\n",
      "# Test that timezone has offset 8 hours (PST) both during summer and winter\n",
      "\n",
      "# Test this timezone.  Confirm epoch time of midnight 1/1/70 was 5 hours\n",
      "date = datetime.datetime.strptime('1/1/1970 00:00', '%m/%d/%Y %H:%M').replace(tzinfo=baaqmd_tz)\n",
      "epoch = (date - datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())).total_seconds()\n",
      "if epoch != 8 * 3600:\n",
      "    raise Exception(\"Error in timezone\")\n",
      "\n",
      "date = datetime.datetime.strptime('7/1/1970 00:00', '%m/%d/%Y %H:%M').replace(tzinfo=baaqmd_tz)\n",
      "epoch = (date - datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())).total_seconds()\n",
      "if epoch % 86400 != 8 * 3600:\n",
      "    raise Exception(\"Error in timezone\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gentleFetch(url):\n",
      "    for i in range(0, 10):\n",
      "        try:\n",
      "            return urllib2.urlopen(url).read()\n",
      "        except Exception, e:\n",
      "            # if it's a HTTP error with code 404, don't retry\n",
      "            try:\n",
      "                if e.code == 404:\n",
      "                    raise\n",
      "            except:\n",
      "                pass\n",
      "            print 'Error %s fetching %s, retrying' % (e, url)\n",
      "            time.sleep(15)\n",
      "            \n",
      "    return urllib2.urlopen(url).read()\n",
      "\n",
      "def makeIdentifier(prettyName):\n",
      "    return re.sub('\\W+', '_', prettyName).strip('_')\n",
      "\n",
      "def getStations():\n",
      "    url = \"http://www.baaqmd.gov/Divisions/Technical-Services/Ambient-Air-Monitoring/Air-Monitoring-Data.aspx?DataViewFormat=daily\"\n",
      "    body = gentleFetch(url)\n",
      "    selector = Selector(text = body)\n",
      "    ids = selector.xpath('//select[contains(@name, \"StationSelect\")]/option/@value').extract()\n",
      "    names = selector.xpath('//select[contains(@name, \"StationSelect\")]/option/text()').extract()\n",
      "    sites = dict(zip(ids, names))\n",
      "    del sites['']\n",
      "    #ret = sorted([id for id in ids if re.match('\\d+', id)])\n",
      "    #print 'All station IDs: %s' % ', '.join(ret)\n",
      "    return sites\n",
      "\n",
      "#getStations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getStationInfo(stationId):\n",
      "    # First look in sites.json\n",
      "    stations = json.load(open('sites.json'))\n",
      "    if stationId in stations:\n",
      "        return stations[stationId]\n",
      "    \n",
      "    html = None\n",
      "    for stationType in ['tec', 'met']:\n",
      "        try:\n",
      "            url = 'http://hank.baaqmd.gov/tec/maps/%ssites%s.htm' % (stationType, stationId)\n",
      "            html = gentleFetch(url)\n",
      "        except urllib2.HTTPError:\n",
      "            pass\n",
      "    if not html:\n",
      "        raise Exception('Cannot find data for station %s' % stationId)\n",
      "    selector = Selector(text = html)\n",
      "    title = selector.xpath('//title/text()').extract()[0]\n",
      "    name = re.search(r\":(.*)\", title).group(1).strip()\n",
      "    name = name.replace(u'\\xa0', ' ')\n",
      "    # For some reason, the page shows longitude as positive instead of negative\n",
      "    return {\n",
      "        'name': name,\n",
      "        'longitude': -abs(float(re.search(r'Longitude.*?(-?\\d+\\.\\d+)', html).group(1))),\n",
      "        'latitude': float(re.search(r'Latitude.*?(-?\\d+\\.\\d+)', html).group(1))\n",
      "    }\n",
      "\n",
      "def printCombinedStationInfo():\n",
      "    for (id, name) in getStations().iteritems():\n",
      "        try:\n",
      "            info = getStationInfo(id)\n",
      "            print '%s\\t%s\\t%s\\t%s\\t%s' % (id, name, info['name'], info['latitude'], info['longitude'])\n",
      "        except:\n",
      "            print '%s\\t%s' % (id, name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getStationFeed(stationId, provisionalStationName):\n",
      "    stationInfo = {}\n",
      "    device = esdr.get_device_by_serial_number(product, stationId)\n",
      "    if not device:\n",
      "        try:\n",
      "            stationInfo = getStationInfo(stationId)\n",
      "        except:\n",
      "            pass\n",
      "        stationName = stationInfo['name'] if 'name' in stationInfo else provisionalStationName\n",
      "        esdr.create_device(product, stationId, name=stationName)\n",
      "        device = esdr.get_device_by_serial_number(product, stationId)\n",
      "\n",
      "    feed = esdr.get_feed(device)\n",
      "    if not feed:\n",
      "        try:\n",
      "            stationInfo = getStationInfo(stationId)\n",
      "        except:\n",
      "            pass\n",
      "        lat = None\n",
      "        lon = None\n",
      "        if 'latitude' in stationInfo:\n",
      "            lat = stationInfo['latitude']\n",
      "            lon = stationInfo['longitude']\n",
      "        esdr.create_feed(device, lat=lat, lon=lon)\n",
      "        feed = esdr.get_feed(device)\n",
      "    \n",
      "    return feed\n",
      "\n",
      "#getStationFeed('1025', 'Oakland East')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def uploadStation(stationId, provisionalStationName, date):\n",
      "    formattedDate = date.strftime('%m/%d/%Y')\n",
      "    channel_names = []\n",
      "    upload_data = []\n",
      "    for hour in range(0, 24):\n",
      "        # Set minute=30 to use timestamp in middle of hourlong sampling period\n",
      "        time = date.replace(hour=hour, minute=30, second=0, microsecond=0, tzinfo=baaqmd_tz)\n",
      "        epoch_time = (time - datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())).total_seconds()\n",
      "        upload_data.append([epoch_time])\n",
      "    \n",
      "    for paramType in ['tech', 'met']:\n",
      "        url = 'http://www.baaqmd.gov/Divisions/Technical-Services/Ambient-Air-Monitoring/Air-Monitoring-Data.aspx?DataViewFormat=daily&DataView=%s&StartDate=%s&ParameterId=&StationId=%s' % (paramType, formattedDate, stationId)\n",
      "        try:\n",
      "            body = gentleFetch(url)\n",
      "        except urllib2.HTTPError:\n",
      "            print 'Error fetching %s' % url\n",
      "            continue\n",
      "        selector = Selector(text = body)\n",
      "        params = selector.xpath('//tr[count(td)>=25]')\n",
      "        for param in params:\n",
      "            param_name = param.xpath('td/a/text()')[0].extract()\n",
      "            channel_names.append(makeIdentifier(param_name))\n",
      "            columns = param.xpath('td/div[@class=\"cData\"]')\n",
      "            for hour in range(0, 24):\n",
      "                column = columns[hour]\n",
      "                if len(column.xpath('text()')):\n",
      "                    upload_data[hour].append(float(column.xpath('text()').extract()[0]))\n",
      "                else:\n",
      "                    upload_data[hour].append(False) # False deletes sample at same time datastore\n",
      "\n",
      "    feed = getStationFeed(stationId, provisionalStationName)\n",
      "\n",
      "    esdr.upload(feed, {\n",
      "        'channel_names': channel_names,\n",
      "        'data': upload_data\n",
      "    })\n",
      "    print 'Uploaded %d channels from %s to %s:%s' % (len(channel_names), date.strftime('%m/%d/%Y'), stationId, provisionalStationName)\n",
      "\n",
      "def uploadStations(date):\n",
      "    for (stationId, provisionalStationName) in getStations().iteritems():\n",
      "        uploadStation(stationId, provisionalStationName, date)\n",
      "\n",
      "#uploadStations(datetime.datetime(2015, 5, 19))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#8 28 2012\n",
      "for date in reversed(list(rrule.rrule(rrule.DAILY, dtstart=datetime.datetime(2015, 5, 15), until=datetime.datetime(2015, 6, 5)))):\n",
      "    uploadStations(date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Uploaded 6 channels from 06/05/2015 to 5011:San Francisco - Arkansas St.\n",
        "Uploaded 5 channels from 06/05/2015 to 2907:Pt. San Pablo"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unneeded\n",
      "\n",
      "def getParams(paramType):\n",
      "    # paramType is tech or met\n",
      "    url = \"http://www.baaqmd.gov/Divisions/Technical-Services/Ambient-Air-Monitoring/Air-Monitoring-Data.aspx?DataViewFormat=daily&DataView=%s\" % paramType\n",
      "    body = gentleFetch(url)\n",
      "    selector = Selector(text = body)\n",
      "    ids = selector.xpath('//select[contains(@name, \"MeasurementSelect\")]/option/@value').extract()\n",
      "    names = selector.xpath('//select[contains(@name, \"MeasurementSelect\")]/option/text()').extract()\n",
      "    parameters = dict(zip(ids, names))\n",
      "    print 'Found %s params from %s: %s' % (paramType, url, parameters)\n",
      "    return parameters\n",
      "\n",
      "# p=getParams('tech')\n",
      "# getParams('met')\n",
      "\n",
      "def getParamFromAllSites(paramType, paramId, date):\n",
      "    url = 'http://www.baaqmd.gov/Divisions/Technical-Services/Ambient-Air-Monitoring/Air-Monitoring-Data.aspx?DataViewFormat=daily&DataView=%s&StartDate=%s&ParameterId=%s' % (paramType, date, paramId)\n",
      "    body = gentleFetch(url)\n",
      "    selector = Selector(text = body)\n",
      "    sites = selector.xpath('//tr[count(td)>=25]')\n",
      "    for site in sites:\n",
      "        sitename = site.xpath('td/a/text()')[0].extract()\n",
      "        values = [float(value) for value in site.xpath('td/div[@class=\"cData\"]/text()').extract()]\n",
      "        print sitename, values\n",
      "\n",
      "# getParamFromAllSites('tech', '59', '5/22/2015')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    }
   ],
   "metadata": {}
  }
 ]
}